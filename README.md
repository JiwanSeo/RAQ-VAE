<<<<<<< HEAD
# VRVQ
This repository contains the official PyTorch/Pytorch-Lightning implementation of **"VRVQ: Variable-Rate VQ-VAE via Codebook Representative Seq2Seq Model"** (**).
```
Please cite [[1](#citation)] in your work when using this code in your experiments.

![](imgs/method.png)
```
> **Abstract:** This paper presents a comprehensive exploration of the Variable-Rate VQ-VAE (VRVQ) framework, which combines the Sequence-to-Sequence (Seq2Seq) model and VQ-VAE. By integrating the Seq2Seq model, the study aims to address the challenge of training separate models for different compression rates in computer vision tasks. We contribute to the development of a new framework for variable-rate image compression and have implications for improving performance while maintaining the existing VQ-VAE structure. Through our experiments, our results demonstrate that the proposed VRVQ model achieves effective reconstruction performance over multiple rates, with comparable performance to conventional fixed-rate VQ-VAE models. This work has important implications for applications in image reconstruction, image compression, and other computer vision tasks, as well as potential extensions to various VQ applications.

```
# Citation
[1] 

# bibtex
```
=======
# RAQ-VAE
RAQ-VAE: Rate-Adaptive Vector-Quantized Variational Autoencoder
>>>>>>> origin/main
